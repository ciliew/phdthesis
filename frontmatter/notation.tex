

$N$ is the number of observations, indexed by $n$

\section{Probability stuff}
we use $\mu$ for the mean. This might be one-dimensional or higher-dimensionsal
we use $\Sigma$ for the covariance and $\sigma$ for a variance

\section{GP stuff}
$q$ is the latent dimensionality, using the index $i$
$d$ is the dataspace dimensionality, using the index $j$
f is a map from low dim to high dim space, most often a Gaussian process


$Q$ is the latent dimensionality and is indexed by $q$
$D$ is the observation dimensionality and is indexed by $d$
$\Xcal$ is the latent space 
$\Ycal$ is the observation space 
$\mathbf{X}$ is the matrix that collect the latent points $\mathbf{X} = \{x_n\}_{n=1}^N$
$\mathbf{Y}$ is the matrix that collect the latent points $\mathbf{Y} = \{y_n\}_{n=1}^N$



J is the Tangent space/jacobian
G is the metric
energy of a curve $\varepsilon$

curve c or $\gamma$
t is a continuous parametrization of the curve
i is a discrete parametrization of the curve



$\mu$ is the mean of the Riemannian Brownian motion
$\nu$ is the variance of the Riemannian Brownian motion




A active set
B Symmetry indicator
C 
D Observation dimensionality
E 
F map, gp
G metric
H betti number thingy
I
J Jacobian
K Lipschitz contuinity
L Loss/elbo
M nof inducing points
N Nog observations
O
P size of hold-out set, Fong2020
Q Latent dimensionality
R Rest set
S Score function
T
U Inducing variables
V Vecotr?
X Latent variables
Y Observations
Z Inducing points
%
%\renewcommand{\arraystretch}{1.5}
%\begin{table}[ht]
%\caption{Partial horizontal line}
%\begin{center}
%\begin{tabular}{cll}
%    \toprule
%    %\multicolumn{2}{c}{Variable}&\multicolumn{1}{c}{Hej}\\
%    \multicolumn{3}{c}{Variable} \\%\vspace{2pt} \\%&\multicolumn{1}{c}{Hej}\\
%    \cline{1-3} %\vspace{2pt}
%    %\cline{1-2}  
%    %\vspace*{2pt} 
%    Name &Dimension& Description\\
%    %\midrule
%    \cmidrule(l){1-1}     \cmidrule(l){2-2} \cmidrule(l){3-3}
%    $N$ 	& $N \in \mathbb{R}$              		& Number of observations        \\
%    $D$ 	& $D \in \mathbb{R}$              		& Number of data dimensions        \\
%    $Q$ 	& $Q \in \mathbb{R}$                		& Latent dimensionality\\
%    $Y$ 	& $Y \in \mathbb{R}^{N\times D}$ 	& Data matrix\\
%    $X$ 	& $X \in \mathbb{R}^{N\times Q}$	& Matrix of input points\\
%    $M$ 	& $M \in \mathbb{R}^{N\times M}$    & Matrix of inducing points\\
%    \cmidrule(l){1-1}     \cmidrule(l){2-2} \cmidrule(l){3-3}
%    \\ \multicolumn{3}{c}{Variable} \\%\vspace{2pt} \\%&\multicolumn{1}{c}{Hej}\\
%    \cline{1-3}
%    Name &Dimension& Description\\
%    \cmidrule(l){1-1}     \cmidrule(l){2-2} \cmidrule(l){3-3}
%    $N$ 	& $N \in \mathbb{R}$              		& Number of observations        \\
%    \bottomrule
%\end{tabular}
%\end{center}
%\label{tab:notation}
%\end{table}
%\todo{finish this table}


  

%| Variable  	        | Code 	                   |Dimension                         | Name      	                                        |
%|----------	          |-------	                 |-----                             |--------	                                            |
%| $Y$    	            | `y`  	                   |$Y \in \mathbb{R}^{N\times D}$    | Data    	                                          |
%| $N$      	          | `N` 	                   |$N \in \mathbb{R}$                | Number of observations                              |
%| $D$         	      | `D`    	                 |$D \in \mathbb{R}$                | Dimensionality of data space                        |
%| $Q$         	      | `Q`    	                 |$Q \in \mathbb{R}$                | Dimensionality of latent space                      |

%| $K=k(x,x')$     	  | `kernel`  	             |$K \in \mathbb{R}^{N\times N}$    | Covariance function, SE ARD (Choice)                |
%| $\theta$ 	          | `kernel.variance`        |$\theta \in \mathbb{R}$           | Kernel variance                                     |
%| $l$     	          | `kernel.lengthscale`     |$l \in \mathbb{R}^q$              | Lengthscale. If kernel is not ARD then $l$ is scalar|
%| $\sigma^2$ 	        | `(model.)noise`          |$\sigma^2 \in \mathbb{R}$         | Noise variance added to the diagonal of the covariance matrix. |
%| $p(X)$ 	            | ????? | |Spherical Gaussian prior for the latent points $X$, $p(X) = \prod_{n=1}^N p(x_n\vert 0,\mathbb{I}_q)$. |
%| $p(Y \vert X)$      | `loss_fn`                | |The likelihood $p(Y \vert X) = \prod_{d=1}^D p(y_d\vert X)$, $y_d$ is a column in $Y$                  |
%| $p(Y)$ 	            | |        | Marginal likelihood                  |
%| $p(X \vert Y)$ 	    | |         | True posterior, intractable|
%| $q(X)$ 	            |`X_loc`,`X_scale`|| Prior on latent variables|
%| $q(X_u)$ 	          |`Xu_loc`,`Xu_scale`|| Prior on location of inducing points|
%| $q(u)$ 	            ||| Prior of function values, sampled from $f$|
%
